{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science (CS4661). Cal State Univ. LA, CS Dept.\n",
    "## Dr. Mo. Porhomayoun\n",
    "----------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Science in Python\n",
    "\n",
    "#### This is an introduction to some data sceince libraries/packages in python. Feel free to refer to the suggested resources and documentaries for more details.\n",
    "\n",
    "----------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Library (sklearn):\n",
    "Scikit-learn is the Python Machine Learning Library. It includes optimal implementation of various classification, regression and clustering algorithms. It also includes hundreds of commands and functions for data preprocessing and processing along with a number of default datasets to work with.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "##    LOGISTIC REGRESSION and DECISION TREE CLASSIFIERS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review: The Main Steps to build (train) and use (test/predict) a predictive model in sklearn:\n",
    "\n",
    "#### Step1: Importing the sklearn class (machine learning algorithm) that you would like to use for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following line will import LogisticRegression and DecisionTreeClassifier Classes\n",
    "# \"LogisticRegression\" and \"DecisionTreeClassifier\" are the names of a \"sklearn classes\" to perform Logistic Regression and Decision Tree based Classification \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "# we will need numpy and pandas later\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: Set up the Feature Matrix and Label Vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading a CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "# \"read_csv\" is a pandas function to read csv files from web or local device:\n",
    "\n",
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "10            5.4          3.7           1.5          0.2      setosa\n",
       "20            5.4          3.4           1.7          0.2      setosa\n",
       "30            4.8          3.1           1.6          0.2      setosa\n",
       "40            5.0          3.5           1.3          0.3      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "60            5.0          2.0           3.5          1.0  versicolor\n",
       "70            5.9          3.2           4.8          1.8  versicolor\n",
       "80            5.5          2.4           3.8          1.1  versicolor\n",
       "90            5.5          2.6           4.4          1.2  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "110           6.5          3.2           5.1          2.0   virginica\n",
       "120           6.9          3.2           5.7          2.3   virginica\n",
       "130           7.4          2.8           6.1          1.9   virginica\n",
       "140           6.7          3.1           5.6          2.4   virginica"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataset by printing every 10 lines:\n",
    "iris_df[0::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Feature Matrix for iris dataset:\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = iris_df[feature_cols]  \n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# checking the size of Feature Matix X:\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          setosa\n",
       "10         setosa\n",
       "20         setosa\n",
       "30         setosa\n",
       "40         setosa\n",
       "50     versicolor\n",
       "60     versicolor\n",
       "70     versicolor\n",
       "80     versicolor\n",
       "90     versicolor\n",
       "100     virginica\n",
       "110     virginica\n",
       "120     virginica\n",
       "130     virginica\n",
       "140     virginica\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a Series of labels (the last column) from the DataFrame\n",
    "y = iris_df['species']\n",
    "\n",
    "# checking the label vector by printing every 10 values\n",
    "y[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3: Defining (instantiating) an \"object\" from the sklearn class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"my_logreg\" is instantiated as an \"object\" of LogisticRegression \"class\". \n",
    "# \"my_decisiontree\" is instantiated as an \"object\" of DecisionTreeClassifier \"class\". \n",
    "\n",
    "\n",
    "my_logreg = LogisticRegression()\n",
    "\n",
    "my_decisiontree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that the name of the object is just an arbitrary name. We usually use a name that makes sense.\n",
    "- To check the adjustable parameters and default values we can refer the sklearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step4: Training Stage: Training a predictive model using the training dataset:\n",
    "\n",
    "#### Method \"fit\" is used for many sklearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the method \"fit\" of the objects \"my_logreg\" and \"my_decisiontree\" along with training dataset and labels to train the model.\n",
    "\n",
    "my_logreg.fit(X, y)\n",
    "\n",
    "my_decisiontree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step5: Testing (Prediction) Stage: Making prediction on new observations (Testing Data) using the trained model:\n",
    "Now, Suppose that we have a new observation (a new data sample) with Known features [6, 3, 5.9, 2.9], and Unknown label. What would be our predition for the label of this new observation?\n",
    "#### Method \"predict\" is used for many sklearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virginica' 'setosa']\n",
      "['virginica' 'setosa']\n"
     ]
    }
   ],
   "source": [
    "# We use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "\n",
    "# Prediction for Two new data samples:\n",
    "\n",
    "X_Testing = [[6, 3, 5.9, 2.9],[3.2, 3, 1.9, 0.3]]\n",
    "\n",
    "y_predict_lr = my_logreg.predict(X_Testing)\n",
    "\n",
    "y_predict_dt = my_decisiontree.predict(X_Testing)\n",
    "\n",
    "print(y_predict_lr)\n",
    "print(y_predict_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluating the accuracy of our classifier:\n",
    "\n",
    "#### Now to evaluate our model, as we learned in previous tutorial, let's split the data into training and testing sets. Then, assuming that we do NOT know the label of Testing Set, we train our model on Training Set and then test it on Testing Set. Then, we compare the \"predicted labels\" against the \"actual labels\" to check the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ONLY on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training ONLY on the training set:\n",
    "\n",
    "my_logreg.fit(X_train, y_train)\n",
    "\n",
    "my_decisiontree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on the testing set:\n",
    "\n",
    "y_predict_lr = my_logreg.predict(X_test)\n",
    "\n",
    "y_predict_dt = my_decisiontree.predict(X_test)\n",
    "\n",
    "# print(y_predict_lr)\n",
    "# print(y_predict_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Evaluation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score_lr = accuracy_score(y_test, y_predict_lr)\n",
    "score_dt = accuracy_score(y_test, y_predict_dt)\n",
    "\n",
    "print(score_lr)\n",
    "print(score_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#   \n",
    "#    LINEAR REGRESSION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following line will import LinearRegression \"Class\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this example, we download and work with a dataset (Advertising.csv) from the Textbook \"An Introduction to Statistical Learning\" \n",
    "\n",
    "##### About Advertising Dataset: \n",
    "Suppose that we want to improve the sales of a particular product using advertisement. The\n",
    "Advertising dataset consists of the sales of that product in 200 different\n",
    "markets, along with advertising budgets for the product in each of those\n",
    "markets for three different media: TV, radio, and newspaper. \n",
    "(reference: An Introduction to Statistical Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Introduction to Statistical Learning:  \n",
    "http://www-bcf.usc.edu/~gareth/ISL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the dataset as a CSV file directly from the book website\n",
    "Ad_data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "\n",
    "# show the first 5 rows\n",
    "Ad_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features:\n",
    "- **TV:** The money spent on TV advertisements for the product in a given market (in 1000 dollars)\n",
    "- **Radio:** The money spent on Radio advertisements for the product (in 1000 dollars)\n",
    "- **Newspaper:** The money spent on Newspaper advertisements for the product (in 1000 dollars)\n",
    "\n",
    "### Target:\n",
    "- **Sales:** sales of the product (in 1000 items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### linear regression model\n",
    "\n",
    "General format for linear regression with multiple variables:\n",
    "\n",
    "$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n$\n",
    "\n",
    "\n",
    "In this example:\n",
    "\n",
    "$y = \\theta_0 + \\theta_1 \\times TV + \\theta_2 \\times Radio + \\theta_3 \\times Newspaper$\n",
    "\n",
    "The $\\theta$ values are the **model coefficients** that will be determined in \"training stage\" by finding the best fitted line. Then, the fitted model will be used in testing stage to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Feature Matrix X and Target Vector y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Feature Matrix:\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "\n",
    "# use the above list to select the features:\n",
    "X = Ad_data[feature_cols]\n",
    "\n",
    "# Another way to do this (notice double bracket!):\n",
    "X = Ad_data[['TV', 'radio', 'newspaper']]\n",
    "\n",
    "# check the size:\n",
    "print(X.shape)\n",
    "\n",
    "# show the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the target (last column) from the DataFrame\n",
    "y = Ad_data['sales']\n",
    "\n",
    "# checking the size of target vector:\n",
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into testing and training:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating and Training Stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the following line, \"my_linreg\" is instantiated as an \"object\" of LinearRegression \"class\". \n",
    "\n",
    "my_linreg = LinearRegression()\n",
    "\n",
    "# fitting the model to the training data:\n",
    "my_linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing Theta0 using attribute \"intercept_\":\n",
    "print(my_linreg.intercept_)\n",
    "\n",
    "# printing [Theta1, Theta2, Theta3] using attribute \"coef_\":\n",
    "print(my_linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus, our predictive model will be: \n",
    "$$y = 3.189 + 0.045 \\times TV + 0.183 \\times Radio + 0.004 \\times Newspaper$$\n",
    "\n",
    "What does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Prediction Stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_prediction = my_linreg.predict(X_test)\n",
    "\n",
    "print(y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "# Evaluation for Regression:\n",
    "- So far we talked about evaluation for claasifiers: For classifiers we compared \"the predicted labels\" against \"the actual labels\" and claculated the accuracy as the percentage of correctly classified samples.\n",
    "- In regression, the target is continous valued. So, we need to find the error as the average difference between the \"predicted target value\" and the \"actual value\".\n",
    "- The most popular metric to quantify this difference (error) is **Root Mean Square Error** or **RMSE**:\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "- \"yi\" is the actual value. \"yi_hat\" is the predicted value.\n",
    "- Notice that **RMSE** is error. So, unlike the accuracy for classifiers, **a lower value for RMSE is better!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Calculating \"Mean Square Error\" (MSE):\n",
    "mse = metrics.mean_squared_error(y_test, y_prediction)\n",
    "\n",
    "# Using numpy sqrt function to take the square root and calculate \"Root Mean Square Error\" (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We saw how to split the dataset into Training and Testing sets, Fit the model on \"training set\", and then predict on \"testing set\" to evaluate the accuracy. **\n",
    "\n",
    "**The problem with this method is that the results may depend on the split. In other word, changing which data samples happen to be in the testing set can change the testing accuracy! For example, if you are lucky, some easily predictable samples may happen to be located in the testing set (or vice versa!). **\n",
    "\n",
    "**In order to get more fair results, we can repeat the splitting process several times, compute the prediction accuracy for each split, and then average the results.**\n",
    "\n",
    "**Cross Validation tries to reapeat the splitting procedure K times in a smart way such that all data samples will be used in \"testing set\" one time and in \"Training Set\" (K-1) times!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three main steps for K-fold cross-validation\n",
    "1. Split the dataset Randomly into K equal, non-overlapping sections.\n",
    "2. Use one of the sections as **testing set** at a time and the union of the other (K-1) sections as the **training set**. Perform training stage, testing stage, and compute the accuracy based on the split each time. Repeat this procedure K times, so that each one of the K sections is used as **testing set** one time, and as a part of **training set** (K-1) times.\n",
    "5. Calculate the average of the accuracies as final result.\n",
    "\n",
    "Note: Using K=10 (10-fold cross-validation) is very common and recommended in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the method:\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying 10-fold Cross Validation for \"logistic regression\" classifier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the iris data:\n",
    "\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# Feature Matrix:\n",
    "X = iris_df[feature_cols] \n",
    "\n",
    "# Label Vector:\n",
    "y = iris_df['species'] \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying 10-fold cross validation with \"logistic regression\" classifier:\n",
    "\n",
    "# In the following line, \"my_logreg\" is instantiated as an \"object\" of LogisticRegression \"class\". \n",
    "my_logreg = LogisticRegression()\n",
    "\n",
    "accuracy_list = cross_val_score(my_logreg, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each element in \"accuracy_list\" above is the accuracy value in one of the K rounds of cross validation. We will use the average of them as the final accuracy for our model.\n",
    "\n",
    "#### As we saw, the method \"cross_val_score\" will take care of everything, including splitting the data, forming Training and Testing sets (K times), Training and Testing the model (K times), and evaluating and reporting the accuracy for each round!\n",
    "\n",
    "#### Now, we only need to calculate the average of the accuracies from K rounds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use average of accuracy values as final result\n",
    "accuracy_cv = accuracy_list.mean()\n",
    "\n",
    "print(accuracy_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying 10-fold Cross Validation for \"linear regression\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Ad dataset:\n",
    "\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "\n",
    "# feature matrix:\n",
    "X = Ad_data[feature_cols]\n",
    "\n",
    "# target vector:\n",
    "y = Ad_data['sales']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying 10-fold cross validation with \"linear regression\":\n",
    "\n",
    "# In the following line, \"my_linreg\" is instantiated as an \"object\" of LinearRegression \"class\". \n",
    "my_linreg = LinearRegression()\n",
    "\n",
    "mse_list = cross_val_score(my_linreg, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you see, we would like to check the \"mean_squared_error\" (mse) for linear regression\n",
    "#### Notice that \"cross_val_score\" by default provides \"negative\" values for \"mse\" to clarify that mse is error. In order to calculate root mean square error (rmse), we have to make them positive, and then find the avergae of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice that \"cross_val_score\" by default provides \"negative\" values for \"mse\" to clarify that mse is error.\n",
    "# in order to calculate root mean square error (rmse), we have to make them positive!\n",
    "mse_list_positive = -mse_list\n",
    "\n",
    "# using numpy sqrt function to calculate rmse:\n",
    "rmse_list = np.sqrt(mse_list_positive)\n",
    "print(rmse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the average RMSE as final result of cross validation:\n",
    "print(rmse_list.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- Documentation of scikit-learn \n",
    "- Documentation of pandas\n",
    "- An Introduction to Statistical Learning: www-bcf.usc.edu/~gareth/ISL\n",
    "- Machine Learning, Andrew Ng\n",
    "- Data school website: www.dataschool.io\n",
    "- kaggle website: www.kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
